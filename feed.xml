<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://musclemuller.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://musclemuller.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-10T09:39:01+00:00</updated><id>https://musclemuller.github.io/feed.xml</id><title type="html">blank</title><subtitle>Software Engineer specializing in Data Infrastructure, Real-Time Analytics, and Distributed Systems </subtitle><entry><title type="html">Building an MCP Server for Real-Time Analytics</title><link href="https://musclemuller.github.io/blog/2025/building-mcp-server-pinot/" rel="alternate" type="text/html" title="Building an MCP Server for Real-Time Analytics"/><published>2025-06-01T19:00:00+00:00</published><updated>2025-06-01T19:00:00+00:00</updated><id>https://musclemuller.github.io/blog/2025/building-mcp-server-pinot</id><content type="html" xml:base="https://musclemuller.github.io/blog/2025/building-mcp-server-pinot/"><![CDATA[<blockquote> <p><strong>Note:</strong> This is a placeholder post. I’ll expand it with the full technical write-up soon.</p> </blockquote> <p>At Uber, I’ve been working on a <a href="https://modelcontextprotocol.io/">Model Context Protocol (MCP)</a> server built on top of Apache Pinot — Uber’s real-time OLAP datastore. The goal: make it easy for LLM agents to reason about Pinot tables, run queries, and troubleshoot issues without requiring users to know the internals of the platform.</p> <h2 id="whats-an-mcp-server">What’s an MCP Server?</h2> <p>MCP is an open protocol that standardizes how LLMs interact with tools and data sources. An MCP server exposes a set of <strong>tools</strong> (functions the LLM can call) and <strong>resources</strong> (data the LLM can read). The LLM decides which tools to call based on user intent, and the server executes them.</p> <h2 id="why-pinot">Why Pinot?</h2> <p>Pinot is a real-time OLAP database designed for low-latency analytical queries over high-throughput event streams. At Uber, it powers dashboards, alerts, and operational analytics for teams across the company. But onboarding a new table or debugging a query issue typically requires understanding Pinot internals — schema formats, segment lifecycles, routing rules, upsert semantics.</p> <p>That’s the gap the MCP server fills.</p> <h2 id="what-the-server-exposes">What the Server Exposes</h2> <p>A few of the tools currently implemented:</p> <ul> <li><code class="language-plaintext highlighter-rouge">list_tables</code> — enumerate all tables in a cluster</li> <li><code class="language-plaintext highlighter-rouge">get_schema</code> — fetch the schema for a given table</li> <li><code class="language-plaintext highlighter-rouge">run_query</code> — execute a PQL/SQL query and return results</li> <li><code class="language-plaintext highlighter-rouge">get_segment_metadata</code> — inspect segment-level health and gaps</li> <li><code class="language-plaintext highlighter-rouge">get_broker_routing</code> — check how queries are routed to segments</li> </ul> <h2 id="multi-agent-layer">Multi-Agent Layer</h2> <p>On top of the MCP server, I built a multi-agent orchestration layer that routes user requests from Slack, an internal chatbot, and Claude Code. Each agent has access to the MCP tools and can chain calls — for example, diagnosing a slow query by first checking routing, then inspecting segment metadata, then running an explain plan.</p> <p>More details on the agent architecture coming in a follow-up post.</p>]]></content><author><name></name></author><category term="pinot"/><category term="mcp"/><category term="real-time-analytics"/><category term="distributed-systems"/><summary type="html"><![CDATA[A placeholder post on building an MCP server on top of Apache Pinot to enable LLM-powered analytics workflows.]]></summary></entry></feed>